{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   passenger_count  trip_distance  pu_zone_id  do_zone_id  enter_airport  \\\n",
      "0                1           3.20         140          79              0   \n",
      "1                1           1.18         237         145              0   \n",
      "2                1           2.21         114         170              0   \n",
      "3                1           2.10          68         107              0   \n",
      "4                2           1.00         249          79              0   \n",
      "\n",
      "   pickup_hour  pickup_minute  pickup_weekday  dropoff_hour  dropoff_minute  \\\n",
      "0            7             34               1             7              46   \n",
      "1            7             23               1             7              29   \n",
      "2            7             19               1             7              32   \n",
      "3            7             34               1             7              43   \n",
      "4            7             59               1             8               5   \n",
      "\n",
      "   trip_duration_minutes  congestion_level  rain  \n",
      "0              11.883333                 2     0  \n",
      "1               6.550000                 2     0  \n",
      "2              12.516667                 2     0  \n",
      "3               9.150000                 2     0  \n",
      "4               5.583333                 2     0  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"./data/dataset_to_train.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['passenger_count', 'trip_distance', 'pu_zone_id', 'do_zone_id',\n",
      "       'enter_airport', 'pickup_hour', 'pickup_minute', 'pickup_weekday',\n",
      "       'dropoff_hour', 'dropoff_minute', 'trip_duration_minutes',\n",
      "       'congestion_level', 'rain'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column names to verify the correct column name\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['trip_distance', 'pu_zone_id', 'do_zone_id', 'pickup_weekday', 'pickup_hour', \n",
    "        'pickup_minute', 'rain', 'enter_airport']]\n",
    "y = df['trip_duration_minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4141568, 8)\n",
      "X_test shape: (1035393, 8)\n",
      "y_train shape: (4141568,)\n",
      "y_test shape: (1035393,)\n"
     ]
    }
   ],
   "source": [
    "# Perform the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "         trip_distance  pu_zone_id  do_zone_id  pickup_weekday  pickup_hour  \\\n",
      "5050631           2.71         142         170               0            4   \n",
      "599797            3.41         229         144               6           18   \n",
      "3720050           2.61         186         141               1            2   \n",
      "4640213           3.70         239         234               0           23   \n",
      "1157552           1.16          48         237               2           16   \n",
      "\n",
      "         pickup_minute  rain  enter_airport  \n",
      "5050631             34     0              0  \n",
      "599797              36     0              0  \n",
      "3720050             32     0              0  \n",
      "4640213             13     0              0  \n",
      "1157552             21     0              0  \n",
      "\n",
      "Testing Dataset:\n",
      "         trip_distance  pu_zone_id  do_zone_id  pickup_weekday  pickup_hour  \\\n",
      "3392987           1.96          42          75               3            3   \n",
      "3146301           4.80         113         239               5            0   \n",
      "3192804           1.30         100         230               5           22   \n",
      "814257            3.23         141          68               3           16   \n",
      "1978120           2.14         263         229               3            2   \n",
      "\n",
      "         pickup_minute  rain  enter_airport  \n",
      "3392987             20     0              0  \n",
      "3146301             56     0              0  \n",
      "3192804             27     0              0  \n",
      "814257              11     0              0  \n",
      "1978120             15     1              0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the training dataset\n",
    "print(\"Training Dataset:\")\n",
    "print(X_train.head())\n",
    "\n",
    "# Display the first few rows of the testing dataset\n",
    "print(\"\\nTesting Dataset:\")\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_distance     float64\n",
      "pu_zone_id          int64\n",
      "do_zone_id          int64\n",
      "pickup_weekday      int64\n",
      "pickup_hour         int64\n",
      "pickup_minute       int64\n",
      "rain                int64\n",
      "enter_airport       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Linear Regression model\n",
    "lin_model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "lin_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_lin = lin_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.65424301 25.50684407 12.90493014 ... 12.44999348 15.1833014\n",
      " 15.25445413]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for Linear Regression: 4.43130663585696\n",
      "Mean Squared Error for Linear Regression: 64.22837658064188\n",
      "Root Mean Squared Error for Linear Regression: 8.014260825593455\n",
      "R-squared (R²) for Linear Regression: 0.3733321065718832\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred_lin)\n",
    "print(\"Mean Absolute Error for Linear Regression:\", mae)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred_lin)\n",
    "print(\"Mean Squared Error for Linear Regression:\", mse)\n",
    "\n",
    "# Calculate the Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error for Linear Regression:\", rmse)\n",
    "\n",
    "# Calculate the R^2 score\n",
    "r2 = r2_score(y_test, y_pred_lin)\n",
    "print(\"R-squared (R²) for Linear Regression:\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Train the model on the training data\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.532698 31.852528 16.852839 ... 13.247412 13.993834 18.776003]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) for XGBoost: 3.4337676799430525\n",
      "Mean Squared Error (MSE) for XGBoost: 51.07423697198124\n",
      "RMSE for XGBoost:  7.146624166134752\n",
      "R-squared (R²) for XGBoost: 0.5016753311288494\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "print(\"Mean Absolute Error (MAE) for XGBoost:\", mae_xgb)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(\"Mean Squared Error (MSE) for XGBoost:\", mse_xgb)\n",
    "\n",
    "RMSE_xgb = np.sqrt(mse_xgb)\n",
    "print(\"RMSE for XGBoost: \",RMSE_xgb)\n",
    "\n",
    "# Calculate R-squared (R²)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(\"R-squared (R²) for XGBoost:\", r2_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[1;32m      3\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,  \u001b[38;5;66;03m# Number of trees\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,    \u001b[38;5;66;03m# Unlimited depth for better accuracy\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,  \u001b[38;5;66;03m# Minimum samples per split\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m  \u001b[38;5;66;03m# Random seed for reproducibility\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=50,  # Number of trees\n",
    "    max_depth=10,    # Unlimited depth for better accuracy\n",
    "    min_samples_split=2,  # Minimum samples per split\n",
    "    random_state=42  # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf= rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) for Random Forest: 3.8426439175460803\n",
      "Mean Squared Error (MSE) for Random Forest: 57.155625230829436\n",
      "RMSE for Random Forest: 7.560133942651376\n",
      "R-squared (R²) for Random Forest: 0.4423400190412713\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "print(\"Mean Absolute Error (MAE) for Random Forest:\", mae_rf)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(\"Mean Squared Error (MSE) for Random Forest:\", mse_rf)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "RMSE_rf = np.sqrt(mse_rf)\n",
    "print(\"RMSE for Random Forest:\", RMSE_rf)\n",
    "\n",
    "# Calculate R-squared (R²)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(\"R-squared (R²) for Random Forest:\", r2_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model XGB has a smaller RMSE compared to Model Linear Regression and Random Forest, which indicates that, on average, the predictions made by Model XGB are closer to the true values than those made by Model Linear and Random Forest . A smaller RMSE value suggests that Model XGB has a better fit to the data and is more accurate in its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize KNN Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the parameter grid for GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 10],                \n",
    "    'weights': ['uniform', 'distance'],       \n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV for hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=18.6min\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=18.7min\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=18.7min\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=18.7min\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=18.7min\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=18.8min\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=18.8min\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=18.8min\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=22.3min\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=23.6min\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=25.7min\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=26.2min\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=26.3min\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=26.4min\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=26.5min\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=27.0min\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=20.8min\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=20.9min\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=20.8min\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=20.9min\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=22.5min\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=23.0min\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=23.2min\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=23.4min\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=19.1min\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=18.9min\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=18.5min\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=18.5min\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=17.9min\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=18.2min\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=19.8min\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=19.2min\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=20.0min\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=19.8min\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=19.5min\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=19.4min\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=19.0min\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=19.1min\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=18.2min\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=18.3min\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=19.9min\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=19.4min\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=19.9min\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=19.8min\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=19.4min\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=19.5min\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=19.3min\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=19.6min\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=31.7min\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=32.3min\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=40.1min\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=40.3min\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=41.4min\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=41.7min\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=43.7min\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=46.0min\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=44.0min\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=44.8min\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=46.0min\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=45.8min\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=51.5min\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=51.2min\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=51.6min\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=50.0min\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=44.7min\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=43.8min\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=37.7min\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=37.6min\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=33.6min\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=34.1min\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time=35.8min\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time=34.9min\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time=34.5min\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time=34.7min\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time=37.2min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time=37.8min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time=38.7min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time=39.3min\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=20.0min\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=19.4min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time=39.5min\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time=39.9min\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=18.4min\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=18.5min\n",
      "[CV] END ...metric=minkowski, n_neighbors=3, weights=uniform; total time=17.6min\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=17.0min\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=15.3min\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=15.2min\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=15.0min\n",
      "[CV] END ..metric=minkowski, n_neighbors=3, weights=distance; total time=15.1min\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=14.7min\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=14.1min\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=12.8min\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=12.8min\n",
      "[CV] END ...metric=minkowski, n_neighbors=5, weights=uniform; total time=12.9min\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=13.0min\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=13.0min\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=13.1min\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=13.5min\n",
      "[CV] END ..metric=minkowski, n_neighbors=5, weights=distance; total time=14.2min\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=17.6min\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=17.6min\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=17.6min\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=18.0min\n",
      "[CV] END ...metric=minkowski, n_neighbors=7, weights=uniform; total time=18.3min\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=18.7min\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=21.1min\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=20.9min\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=21.3min\n",
      "[CV] END ..metric=minkowski, n_neighbors=7, weights=distance; total time=21.3min\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=25.9min\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=27.4min\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=28.0min\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=27.7min\n",
      "[CV] END ..metric=minkowski, n_neighbors=10, weights=uniform; total time=28.2min\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=27.5min\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=23.6min\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=23.5min\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=17.1min\n",
      "[CV] END .metric=minkowski, n_neighbors=10, weights=distance; total time=15.0min\n",
      "Best Parameters from GridSearchCV: {'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV to find the best hyperparameters\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters found by GridSearchCV\n",
    "print(f\"Best Parameters from GridSearchCV: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best KNN model from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_advanced = KNeighborsRegressor(n_neighbors=10, metric='manhattan', weights='distance', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.08741536 30.3023562  12.87976475 ... 13.99919352 14.58100134\n",
      " 18.12939399]\n"
     ]
    }
   ],
   "source": [
    "#knn_advanced = grid_search.best_estimator_\n",
    "y_pred_knn = knn_advanced.predict(X_test_scaled)\n",
    "print(y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) for Advanced KNN: 3.691612715381257\n",
      "Mean Squared Error (MSE) for Advanced KNN: 57.86367222078017\n",
      "RMSE for Advanced KNN: 7.606817483072679\n",
      "R-squared (R²) for Advanced KNN: 0.435431696906063\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae_knn = mean_absolute_error(y_test, y_pred_knn)\n",
    "print(\"Mean Absolute Error (MAE) for Advanced KNN:\", mae_knn)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "print(\"Mean Squared Error (MSE) for Advanced KNN:\", mse_knn)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "RMSE_knn = np.sqrt(mse_knn)\n",
    "print(\"RMSE for Advanced KNN:\", RMSE_knn)\n",
    "\n",
    "# Calculate R-squared (R²)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "print(\"R-squared (R²) for Advanced KNN:\", r2_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard kNN Performance:\n",
      "MAE: 3.9544796871010965\n",
      "MSE: 62.91711152752842\n",
      "RMSE: 7.932030731630357\n",
      "R-squared: 0.38612594867575134\n",
      "\n",
      "Advanced kNN Performance:\n",
      "MAE: 3.691612715381257\n",
      "MSE: 57.86367222078017\n",
      "RMSE: 7.606817483072679\n",
      "R-squared: 0.435431696906063\n"
     ]
    }
   ],
   "source": [
    "knn_standard = KNeighborsRegressor(n_neighbors=5, metric='euclidean', weights='uniform', n_jobs=-1)\n",
    "knn_standard.fit(X_train, y_train)\n",
    "\n",
    "y_pred_standard = knn_standard.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the standard kNN model\n",
    "mae_standard = mean_absolute_error(y_test, y_pred_standard)\n",
    "mse_standard = mean_squared_error(y_test, y_pred_standard)\n",
    "rmse_standard = np.sqrt(mse_standard)\n",
    "r2_standard = r2_score(y_test, y_pred_standard)\n",
    "\n",
    "print(\"Standard kNN Performance:\")\n",
    "print(f\"MAE: {mae_standard}\")\n",
    "print(f\"MSE: {mse_standard}\")\n",
    "print(f\"RMSE: {rmse_standard}\")\n",
    "print(f\"R-squared: {r2_standard}\")\n",
    "\n",
    "print(\"\\nAdvanced kNN Performance:\")\n",
    "print(f\"MAE: {mae_knn}\")\n",
    "print(f\"MSE: {mse_knn}\")\n",
    "print(f\"RMSE: {RMSE_knn}\")\n",
    "print(f\"R-squared: {r2_knn}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save trained model with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aknn_model.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'aknn_model.joblib'\n",
    "joblib.dump(knn, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1032777\n",
      "           1       0.12      0.02      0.04      2439\n",
      "           2       0.00      0.00      0.00        83\n",
      "           3       0.20      0.05      0.08        21\n",
      "           4       0.00      0.00      0.00        13\n",
      "           5       0.00      0.00      0.00        12\n",
      "           6       1.00      0.02      0.04        48\n",
      "\n",
      "    accuracy                           1.00   1035393\n",
      "   macro avg       0.33      0.16      0.16   1035393\n",
      "weighted avg       1.00      1.00      1.00   1035393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define bins for classification\n",
    "bins = [60, 120, 180, 240, 300, 360, np.inf]\n",
    "\n",
    "labels = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Bin the actual and predicted values\n",
    "y_test_binned = pd.cut(y_test, bins=bins, labels=labels)\n",
    "y_predict_binned = pd.cut(y_pred_knn, bins=bins, labels=labels)\n",
    "\n",
    "# Convert to Series to use cat accessor\n",
    "y_test_binned = pd.Series(y_test_binned).cat.add_categories([0]).fillna(0)\n",
    "y_predict_binned = pd.Series(y_predict_binned).cat.add_categories([0]).fillna(0)\n",
    "\n",
    "# check results\n",
    "print(classification_report(y_test_binned, y_predict_binned)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
